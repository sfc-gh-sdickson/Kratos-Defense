{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kratos Defense ML Models - Model Registry\n",
        "\n",
        "This notebook trains ML models for the Kratos Defense Intelligence Agent:\n",
        "- **Program Risk Prediction** - Predict risk level for defense programs\n",
        "- **Supplier Risk Prediction** - Identify suppliers at risk based on performance\n",
        "- **Asset Maintenance Prediction** - Predict maintenance urgency for assets\n",
        "\n",
        "All models are registered to Snowflake Model Registry and can be added as tools to the Intelligence Agent.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "**Required Packages** (configured automatically):\n",
        "- `snowflake-ml-python`\n",
        "- `scikit-learn`\n",
        "- `xgboost`\n",
        "- `matplotlib`\n",
        "\n",
        "**Database Context:**\n",
        "- **Database:** KRATOS_INTELLIGENCE  \n",
        "- **Schema:** ANALYTICS  \n",
        "- **Warehouse:** KRATOS_WH\n",
        "\n",
        "**Note:** This notebook uses Snowflake Model Registry. Ensure you have appropriate permissions to create and register models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Python packages\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "from snowflake.snowpark import Window\n",
        "\n",
        "# Import Snowpark ML\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context - MUST MATCH 01_database_and_schema.sql\n",
        "session.use_database('KRATOS_INTELLIGENCE')\n",
        "session.use_schema('ANALYTICS')\n",
        "session.use_warehouse('KRATOS_WH')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n",
        "print(f\"   Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"   Database.Schema: {session.get_fully_qualified_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 1: Program Risk Prediction\n",
        "\n",
        "Predict program risk level based on budget, schedule, and milestone performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get program risk data with features\n",
        "# COLUMN NAMES VERIFIED against 02_create_tables.sql PROGRAMS table\n",
        "# All numeric columns explicitly cast to ::FLOAT to avoid Decimal conversion warnings\n",
        "program_risk_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    p.program_id,\n",
        "    p.budget_amount::FLOAT AS budget,\n",
        "    p.spent_amount::FLOAT AS spent,\n",
        "    p.budget_variance::FLOAT AS variance,\n",
        "    p.schedule_variance_days::FLOAT AS schedule_variance,\n",
        "    p.percent_complete::FLOAT AS completion_pct,\n",
        "    p.milestone_count::FLOAT AS total_milestones,\n",
        "    COALESCE((p.milestones_completed::FLOAT / NULLIF(p.milestone_count, 0) * 100), 0)::FLOAT AS milestone_pct,\n",
        "    COALESCE((p.spent_amount::FLOAT / NULLIF(p.budget_amount, 0) * 100), 0)::FLOAT AS budget_utilization,\n",
        "    p.program_type AS prog_type,\n",
        "    CASE p.risk_level\n",
        "        WHEN 'LOW' THEN 0\n",
        "        WHEN 'MEDIUM' THEN 1\n",
        "        WHEN 'HIGH' THEN 2\n",
        "        ELSE 3\n",
        "    END AS risk_label\n",
        "FROM RAW.PROGRAMS p\n",
        "WHERE p.program_status IN ('ACTIVE', 'COMPLETED', 'ON_HOLD')\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Program risk data: {program_risk_df.count()} program records\")\n",
        "program_risk_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_program, test_program = program_risk_df.random_split([0.8, 0.2], seed=42)\n",
        "train_program = train_program.drop(\"PROGRAM_ID\")\n",
        "test_program = test_program.drop(\"PROGRAM_ID\")\n",
        "\n",
        "print(f\"Training set: {train_program.count()} rows\")\n",
        "print(f\"Test set: {test_program.count()} rows\")\n",
        "\n",
        "# Create pipeline with preprocessing and classification\n",
        "program_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"PROG_TYPE\"],\n",
        "        output_cols=[\"PROG_TYPE_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"BUDGET\", \"SPENT\", \"VARIANCE\", \"SCHEDULE_VARIANCE\", \"COMPLETION_PCT\", \"TOTAL_MILESTONES\", \"MILESTONE_PCT\", \"BUDGET_UTILIZATION\"],\n",
        "        output_cols=[\"BUDGET_SCALED\", \"SPENT_SCALED\", \"VARIANCE_SCALED\", \"SCHEDULE_VARIANCE_SCALED\", \"COMPLETION_PCT_SCALED\", \"TOTAL_MILESTONES_SCALED\", \"MILESTONE_PCT_SCALED\", \"BUDGET_UTILIZATION_SCALED\"]\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"RISK_LABEL\"],\n",
        "        output_cols=[\"PREDICTED_RISK\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "program_pipeline.fit(train_program)\n",
        "print(\"✅ Program risk prediction model trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate and register program risk model\n",
        "program_predictions = program_pipeline.predict(test_program)\n",
        "\n",
        "accuracy = accuracy_score(\n",
        "    df=program_predictions, \n",
        "    y_true_col_names=\"RISK_LABEL\", \n",
        "    y_pred_col_names=\"PREDICTED_RISK\"\n",
        ")\n",
        "\n",
        "program_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Model metrics: {program_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=program_pipeline,\n",
        "    model_name=\"PROGRAM_RISK_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts program risk level using Random Forest based on budget, schedule, and milestone performance\",\n",
        "    metrics=program_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Program risk model registered to Model Registry as PROGRAM_RISK_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 2: Supplier Risk Prediction\n",
        "\n",
        "Predict supplier risk level based on quality and delivery performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get supplier risk data with features\n",
        "# COLUMN NAMES VERIFIED against 02_create_tables.sql SUPPLIERS table\n",
        "# All numeric columns explicitly cast to ::FLOAT to avoid Decimal conversion warnings\n",
        "supplier_risk_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    s.supplier_id,\n",
        "    s.quality_rating::FLOAT AS quality_score,\n",
        "    s.delivery_rating::FLOAT AS delivery_score,\n",
        "    ((s.quality_rating + s.delivery_rating) / 2)::FLOAT AS overall_rating,\n",
        "    s.total_orders::FLOAT AS order_count,\n",
        "    s.total_spend::FLOAT AS total_spend,\n",
        "    COALESCE((s.total_spend::FLOAT / NULLIF(s.total_orders, 0)), 0)::FLOAT AS avg_order_value,\n",
        "    s.payment_terms::FLOAT AS payment_terms,\n",
        "    s.supplier_type AS sup_type,\n",
        "    CASE s.risk_rating\n",
        "        WHEN 'LOW' THEN 0\n",
        "        WHEN 'MEDIUM' THEN 1\n",
        "        WHEN 'HIGH' THEN 2\n",
        "        ELSE 3\n",
        "    END AS risk_label\n",
        "FROM RAW.SUPPLIERS s\n",
        "WHERE s.supplier_status IN ('ACTIVE', 'PREFERRED', 'PROBATION')\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Supplier risk data: {supplier_risk_df.count()} supplier records\")\n",
        "supplier_risk_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_supplier, test_supplier = supplier_risk_df.random_split([0.8, 0.2], seed=42)\n",
        "train_supplier = train_supplier.drop(\"SUPPLIER_ID\")\n",
        "test_supplier = test_supplier.drop(\"SUPPLIER_ID\")\n",
        "\n",
        "print(f\"Training set: {train_supplier.count()} rows\")\n",
        "print(f\"Test set: {test_supplier.count()} rows\")\n",
        "\n",
        "# Create pipeline for supplier risk prediction\n",
        "supplier_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"SUP_TYPE\"],\n",
        "        output_cols=[\"SUP_TYPE_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"QUALITY_SCORE\", \"DELIVERY_SCORE\", \"OVERALL_RATING\", \"ORDER_COUNT\", \"TOTAL_SPEND\", \"AVG_ORDER_VALUE\", \"PAYMENT_TERMS\"],\n",
        "        output_cols=[\"QUALITY_SCORE_SCALED\", \"DELIVERY_SCORE_SCALED\", \"OVERALL_RATING_SCALED\", \"ORDER_COUNT_SCALED\", \"TOTAL_SPEND_SCALED\", \"AVG_ORDER_VALUE_SCALED\", \"PAYMENT_TERMS_SCALED\"]\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"RISK_LABEL\"],\n",
        "        output_cols=[\"PREDICTED_RISK\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "supplier_pipeline.fit(train_supplier)\n",
        "print(\"✅ Supplier risk prediction model trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate and register supplier risk model\n",
        "supplier_predictions = supplier_pipeline.predict(test_supplier)\n",
        "\n",
        "accuracy = accuracy_score(\n",
        "    df=supplier_predictions, \n",
        "    y_true_col_names=\"RISK_LABEL\", \n",
        "    y_pred_col_names=\"PREDICTED_RISK\"\n",
        ")\n",
        "\n",
        "supplier_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Model metrics: {supplier_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg.log_model(\n",
        "    model=supplier_pipeline,\n",
        "    model_name=\"SUPPLIER_RISK_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts supplier risk level using Random Forest based on quality and delivery performance\",\n",
        "    metrics=supplier_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Supplier risk model registered to Model Registry as SUPPLIER_RISK_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 3: Asset Maintenance Prediction\n",
        "\n",
        "Predict maintenance urgency for assets based on usage and maintenance history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get asset maintenance data with features\n",
        "# COLUMN NAMES VERIFIED against 02_create_tables.sql ASSETS table\n",
        "# All numeric columns explicitly cast to ::FLOAT to avoid Decimal conversion warnings\n",
        "asset_maintenance_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    a.asset_id,\n",
        "    a.total_flight_hours::FLOAT AS flight_hours,\n",
        "    a.maintenance_interval_hours::FLOAT AS maint_interval,\n",
        "    COALESCE((a.total_flight_hours::FLOAT / NULLIF(a.maintenance_interval_hours, 0) * 100), 0)::FLOAT AS utilization_pct,\n",
        "    DATEDIFF('day', a.last_maintenance_date, CURRENT_DATE())::FLOAT AS days_since_maintenance,\n",
        "    DATEDIFF('day', CURRENT_DATE(), a.next_maintenance_due)::FLOAT AS days_until_due,\n",
        "    CASE a.condition_rating\n",
        "        WHEN 'EXCELLENT' THEN 4\n",
        "        WHEN 'GOOD' THEN 3\n",
        "        WHEN 'FAIR' THEN 2\n",
        "        ELSE 1\n",
        "    END::FLOAT AS condition_score,\n",
        "    CASE WHEN a.mission_ready = TRUE THEN 1 ELSE 0 END::FLOAT AS is_ready,\n",
        "    a.asset_type AS ast_type,\n",
        "    -- Urgency label based on maintenance due date\n",
        "    CASE \n",
        "        WHEN DATEDIFF('day', CURRENT_DATE(), a.next_maintenance_due) < 0 THEN 2  -- OVERDUE\n",
        "        WHEN DATEDIFF('day', CURRENT_DATE(), a.next_maintenance_due) <= 14 THEN 1  -- DUE_SOON\n",
        "        ELSE 0  -- ON_SCHEDULE\n",
        "    END AS urgency_label\n",
        "FROM RAW.ASSETS a\n",
        "WHERE a.asset_status IN ('OPERATIONAL', 'MAINTENANCE', 'STANDBY')\n",
        "  AND a.next_maintenance_due IS NOT NULL\n",
        "  AND a.last_maintenance_date IS NOT NULL\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Asset maintenance data: {asset_maintenance_df.count()} asset records\")\n",
        "asset_maintenance_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_asset, test_asset = asset_maintenance_df.random_split([0.8, 0.2], seed=42)\n",
        "train_asset = train_asset.drop(\"ASSET_ID\")\n",
        "test_asset = test_asset.drop(\"ASSET_ID\")\n",
        "\n",
        "print(f\"Training set: {train_asset.count()} rows\")\n",
        "print(f\"Test set: {test_asset.count()} rows\")\n",
        "\n",
        "# Create pipeline for asset maintenance prediction\n",
        "asset_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"AST_TYPE\"],\n",
        "        output_cols=[\"AST_TYPE_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"FLIGHT_HOURS\", \"MAINT_INTERVAL\", \"UTILIZATION_PCT\", \"DAYS_SINCE_MAINTENANCE\", \"DAYS_UNTIL_DUE\", \"CONDITION_SCORE\", \"IS_READY\"],\n",
        "        output_cols=[\"FLIGHT_HOURS_SCALED\", \"MAINT_INTERVAL_SCALED\", \"UTILIZATION_PCT_SCALED\", \"DAYS_SINCE_MAINTENANCE_SCALED\", \"DAYS_UNTIL_DUE_SCALED\", \"CONDITION_SCORE_SCALED\", \"IS_READY_SCALED\"]\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"URGENCY_LABEL\"],\n",
        "        output_cols=[\"PREDICTED_URGENCY\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "asset_pipeline.fit(train_asset)\n",
        "print(\"✅ Asset maintenance prediction model trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate and register asset maintenance model\n",
        "asset_predictions = asset_pipeline.predict(test_asset)\n",
        "\n",
        "accuracy = accuracy_score(\n",
        "    df=asset_predictions,\n",
        "    y_true_col_names=\"URGENCY_LABEL\",\n",
        "    y_pred_col_names=\"PREDICTED_URGENCY\"\n",
        ")\n",
        "\n",
        "asset_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Model metrics: {asset_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg.log_model(\n",
        "    model=asset_pipeline,\n",
        "    model_name=\"ASSET_MAINTENANCE_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts asset maintenance urgency using Random Forest based on usage and condition\",\n",
        "    metrics=asset_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Asset maintenance model registered to Model Registry as ASSET_MAINTENANCE_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All 3 models have been trained and registered to Snowflake Model Registry:\n",
        "\n",
        "| Model | Type | Output Column | Purpose |\n",
        "|-------|------|---------------|---------|\n",
        "| `PROGRAM_RISK_PREDICTOR` | RandomForestClassifier | `PREDICTED_RISK` | Predicts program risk level |\n",
        "| `SUPPLIER_RISK_PREDICTOR` | RandomForestClassifier | `PREDICTED_RISK` | Identifies supplier risk |\n",
        "| `ASSET_MAINTENANCE_PREDICTOR` | RandomForestClassifier | `PREDICTED_URGENCY` | Predicts maintenance urgency |\n",
        "\n",
        "**Next Steps:**\n",
        "1. Run `sql/ml/07_create_model_wrapper_functions.sql` to create stored procedures that wrap these models\n",
        "2. Run `sql/agent/08_create_intelligence_agent.sql` to create the Intelligence Agent with ML tools\n",
        "3. Test the agent in Snowsight under AI & ML > Agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify all models are registered\n",
        "print(\"=\" * 60)\n",
        "print(\"VERIFICATION: Models registered in Model Registry\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# List all models in registry\n",
        "models = reg.show_models()\n",
        "print(models)\n",
        "\n",
        "print(\"\\n✅ All 3 models registered successfully!\")\n",
        "print(\"   - PROGRAM_RISK_PREDICTOR\")\n",
        "print(\"   - SUPPLIER_RISK_PREDICTOR\")\n",
        "print(\"   - ASSET_MAINTENANCE_PREDICTOR\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
