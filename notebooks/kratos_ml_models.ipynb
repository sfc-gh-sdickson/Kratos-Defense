{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kratos Defense ML Models - Model Registry\n",
        "\n",
        "This notebook trains ML models for the Kratos Defense Intelligence Agent:\n",
        "- **Program Risk Prediction** - Predict likelihood of program schedule/cost issues\n",
        "- **Supplier Risk Prediction** - Identify suppliers at risk of performance issues\n",
        "- **Production Forecaster** - Forecast production throughput and capacity\n",
        "\n",
        "All models are registered to Snowflake Model Registry and can be added as tools to the Intelligence Agent.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "**Required Packages** (configured automatically):\n",
        "- `snowflake-ml-python`\n",
        "- `scikit-learn`\n",
        "- `xgboost`\n",
        "- `matplotlib`\n",
        "\n",
        "**Database Context:**\n",
        "- **Database:** KRATOS_INTELLIGENCE  \n",
        "- **Schema:** ANALYTICS  \n",
        "- **Warehouse:** KRATOS_WH\n",
        "\n",
        "**Note:** This notebook uses Snowflake Model Registry. Ensure you have appropriate permissions to create and register models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Python packages\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "from snowflake.snowpark import Window\n",
        "\n",
        "# Import Snowpark ML\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context - MUST MATCH 01_database_and_schema.sql\n",
        "session.use_database('KRATOS_INTELLIGENCE')\n",
        "session.use_schema('ANALYTICS')\n",
        "session.use_warehouse('KRATOS_WH')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n",
        "print(f\"   Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"   Database.Schema: {session.get_fully_qualified_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 1: Program Risk Prediction\n",
        "\n",
        "Predict whether a program is at risk of schedule delays or cost overruns based on program metrics and history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get program risk data with features\n",
        "# COLUMN NAMES VERIFIED against 02_create_tables.sql\n",
        "program_risk_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    p.program_id,\n",
        "    DATEDIFF('day', p.start_date, COALESCE(p.planned_end_date, CURRENT_DATE()))::FLOAT AS program_duration_days,\n",
        "    p.total_contract_value::FLOAT AS contract_value,\n",
        "    p.funded_value::FLOAT AS funded_value,\n",
        "    COALESCE(p.cost_variance_pct, 0)::FLOAT AS cost_variance,\n",
        "    COALESCE(p.schedule_variance_pct, 0)::FLOAT AS schedule_variance,\n",
        "    COALESCE(p.technology_readiness_level, 5)::FLOAT AS trl,\n",
        "    p.program_type AS program_type,\n",
        "    p.classification_level AS classification,\n",
        "    -- Create risk label based on variance thresholds\n",
        "    CASE \n",
        "        WHEN p.risk_level IN ('HIGH', 'CRITICAL') THEN 1\n",
        "        WHEN COALESCE(p.cost_variance_pct, 0) < -10 THEN 1\n",
        "        WHEN COALESCE(p.schedule_variance_pct, 0) < -15 THEN 1\n",
        "        ELSE 0\n",
        "    END AS is_at_risk\n",
        "FROM RAW.PROGRAMS p\n",
        "WHERE p.program_status IN ('ACTIVE', 'COMPLETED')\n",
        "  AND p.start_date IS NOT NULL\n",
        "LIMIT 10000\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Program risk data: {program_risk_df.count()} program records\")\n",
        "program_risk_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_prog, test_prog = program_risk_df.random_split([0.8, 0.2], seed=42)\n",
        "train_prog = train_prog.drop(\"PROGRAM_ID\")\n",
        "test_prog = test_prog.drop(\"PROGRAM_ID\")\n",
        "\n",
        "# Create pipeline with preprocessing and classification\n",
        "program_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"PROGRAM_TYPE\", \"CLASSIFICATION\"],\n",
        "        output_cols=[\"PROGRAM_TYPE_ENC\", \"CLASSIFICATION_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"PROGRAM_DURATION_DAYS\", \"CONTRACT_VALUE\", \"FUNDED_VALUE\", \"COST_VARIANCE\", \"SCHEDULE_VARIANCE\", \"TRL\"],\n",
        "        output_cols=[\"DURATION_SCALED\", \"CONTRACT_SCALED\", \"FUNDED_SCALED\", \"CV_SCALED\", \"SV_SCALED\", \"TRL_SCALED\"]\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_AT_RISK\"],\n",
        "        output_cols=[\"PREDICTED_RISK\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "program_pipeline.fit(train_prog)\n",
        "print(\"✅ Program risk prediction model trained\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate and register program risk model\n",
        "prog_predictions = program_pipeline.predict(test_prog)\n",
        "\n",
        "accuracy = accuracy_score(\n",
        "    df=prog_predictions, \n",
        "    y_true_col_names=\"IS_AT_RISK\", \n",
        "    y_pred_col_names=\"PREDICTED_RISK\"\n",
        ")\n",
        "\n",
        "prog_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Model metrics: {prog_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=program_pipeline,\n",
        "    model_name=\"PROGRAM_RISK_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts likelihood of program schedule/cost risk using Random Forest based on program metrics\",\n",
        "    metrics=prog_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Program risk model registered to Model Registry as PROGRAM_RISK_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 2: Supplier Risk Prediction\n",
        "\n",
        "Identify suppliers at risk of quality or delivery performance issues.\n",
        "\n",
        "**CRITICAL:** Column names and data types MUST match `07_create_model_wrapper_functions.sql` EXACTLY.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get supplier risk data with features\n",
        "supplier_risk_df = session.sql(\"\"\"\n",
        "WITH supplier_metrics AS (\n",
        "    SELECT\n",
        "        s.supplier_id,\n",
        "        s.supplier_tier::FLOAT AS supplier_tier,\n",
        "        COALESCE(s.quality_rating, 75)::FLOAT AS quality_rating,\n",
        "        COALESCE(s.delivery_rating, 75)::FLOAT AS delivery_rating,\n",
        "        COALESCE(s.overall_rating, 75)::FLOAT AS overall_rating,\n",
        "        s.supplier_type,\n",
        "        CASE WHEN s.is_small_business = TRUE THEN 1 ELSE 0 END AS is_small_business,\n",
        "        COALESCE(AVG(sp.quality_score), 75)::FLOAT AS avg_quality_score,\n",
        "        COALESCE(AVG(sp.on_time_delivery_pct), 85)::FLOAT AS avg_otd_pct,\n",
        "        COALESCE(AVG(sp.defect_rate_pct), 2)::FLOAT AS avg_defect_rate,\n",
        "        COALESCE(SUM(sp.total_orders), 0)::FLOAT AS total_orders,\n",
        "        COALESCE(SUM(sp.late_orders), 0)::FLOAT AS late_orders,\n",
        "        COALESCE(SUM(sp.corrective_actions_issued), 0)::FLOAT AS cars_issued\n",
        "    FROM RAW.SUPPLIERS s\n",
        "    LEFT JOIN RAW.SUPPLIER_PERFORMANCE sp ON s.supplier_id = sp.supplier_id\n",
        "    WHERE s.is_active = TRUE\n",
        "    GROUP BY s.supplier_id, s.supplier_tier, s.quality_rating, s.delivery_rating, \n",
        "             s.overall_rating, s.supplier_type, s.is_small_business\n",
        ")\n",
        "SELECT\n",
        "    supplier_id,\n",
        "    supplier_tier,\n",
        "    quality_rating,\n",
        "    delivery_rating,\n",
        "    overall_rating,\n",
        "    supplier_type,\n",
        "    is_small_business,\n",
        "    avg_quality_score,\n",
        "    avg_otd_pct,\n",
        "    avg_defect_rate,\n",
        "    total_orders,\n",
        "    late_orders,\n",
        "    cars_issued,\n",
        "    CASE \n",
        "        WHEN avg_quality_score < 70 THEN 1\n",
        "        WHEN avg_otd_pct < 80 THEN 1\n",
        "        WHEN avg_defect_rate > 5 THEN 1\n",
        "        WHEN cars_issued > 3 THEN 1\n",
        "        ELSE 0\n",
        "    END AS is_at_risk\n",
        "FROM supplier_metrics\n",
        "LIMIT 5000\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Supplier risk data: {supplier_risk_df.count()} supplier records\")\n",
        "supplier_risk_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train supplier risk model\n",
        "train_sup, test_sup = supplier_risk_df.random_split([0.8, 0.2], seed=42)\n",
        "train_sup = train_sup.drop(\"SUPPLIER_ID\")\n",
        "test_sup = test_sup.drop(\"SUPPLIER_ID\")\n",
        "\n",
        "supplier_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"SUPPLIER_TYPE\"],\n",
        "        output_cols=[\"SUPPLIER_TYPE_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"SUPPLIER_TIER\", \"QUALITY_RATING\", \"DELIVERY_RATING\", \"OVERALL_RATING\", \n",
        "                    \"AVG_QUALITY_SCORE\", \"AVG_OTD_PCT\", \"AVG_DEFECT_RATE\", \"TOTAL_ORDERS\", \"LATE_ORDERS\", \"CARS_ISSUED\"],\n",
        "        output_cols=[\"TIER_SCALED\", \"QUAL_SCALED\", \"DEL_SCALED\", \"OVERALL_SCALED\",\n",
        "                     \"AVG_QUAL_SCALED\", \"OTD_SCALED\", \"DEFECT_SCALED\", \"ORDERS_SCALED\", \"LATE_SCALED\", \"CARS_SCALED\"]\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_AT_RISK\"],\n",
        "        output_cols=[\"PREDICTED_RISK\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "supplier_pipeline.fit(train_sup)\n",
        "print(\"✅ Supplier risk prediction model trained\")\n",
        "\n",
        "# Evaluate and register\n",
        "sup_predictions = supplier_pipeline.predict(test_sup)\n",
        "accuracy = accuracy_score(df=sup_predictions, y_true_col_names=\"IS_AT_RISK\", y_pred_col_names=\"PREDICTED_RISK\")\n",
        "sup_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Model metrics: {sup_metrics}\")\n",
        "\n",
        "reg.log_model(\n",
        "    model=supplier_pipeline,\n",
        "    model_name=\"SUPPLIER_RISK_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts supplier performance risk using Random Forest based on quality and delivery metrics\",\n",
        "    metrics=sup_metrics\n",
        ")\n",
        "print(\"✅ Supplier risk model registered to Model Registry as SUPPLIER_RISK_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 3: Production Forecaster\n",
        "\n",
        "Forecast production throughput based on historical production metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get monthly production data for forecasting\n",
        "production_forecast_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    MONTH(wo.planned_start_date) AS month_num,\n",
        "    YEAR(wo.planned_start_date) AS year_num,\n",
        "    COUNT(DISTINCT wo.work_order_id)::FLOAT AS work_order_count,\n",
        "    SUM(wo.quantity_ordered)::FLOAT AS total_quantity_ordered,\n",
        "    SUM(wo.quantity_completed)::FLOAT AS total_quantity_completed,\n",
        "    COALESCE(AVG(wo.estimated_hours), 100)::FLOAT AS avg_estimated_hours,\n",
        "    COALESCE(AVG(wo.actual_hours), 100)::FLOAT AS avg_actual_hours,\n",
        "    COALESCE(SUM(wo.estimated_cost), 1000000)::FLOAT AS total_estimated_cost,\n",
        "    COUNT(DISTINCT wo.work_order_id)::FLOAT AS production_count\n",
        "FROM RAW.PRODUCTION_ORDERS wo\n",
        "WHERE wo.planned_start_date >= DATEADD('year', -3, CURRENT_DATE())\n",
        "  AND wo.work_order_status IN ('COMPLETED', 'IN_PROGRESS')\n",
        "GROUP BY MONTH(wo.planned_start_date), YEAR(wo.planned_start_date)\n",
        "ORDER BY year_num, month_num\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Production forecast data: {production_forecast_df.count()} monthly records\")\n",
        "production_forecast_df.show(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train production forecaster model\n",
        "train_prod, test_prod = production_forecast_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "production_pipeline = Pipeline([\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"WORK_ORDER_COUNT\", \"TOTAL_QUANTITY_ORDERED\", \"TOTAL_QUANTITY_COMPLETED\", \n",
        "                    \"AVG_ESTIMATED_HOURS\", \"AVG_ACTUAL_HOURS\", \"TOTAL_ESTIMATED_COST\"],\n",
        "        output_cols=[\"WO_SCALED\", \"QTY_ORD_SCALED\", \"QTY_COMP_SCALED\", \n",
        "                     \"EST_HRS_SCALED\", \"ACT_HRS_SCALED\", \"EST_COST_SCALED\"]\n",
        "    )),\n",
        "    (\"Regressor\", LinearRegression(\n",
        "        input_cols=[\"MONTH_NUM\", \"YEAR_NUM\", \"WO_SCALED\", \"QTY_ORD_SCALED\", \"QTY_COMP_SCALED\", \n",
        "                    \"EST_HRS_SCALED\", \"ACT_HRS_SCALED\", \"EST_COST_SCALED\"],\n",
        "        label_cols=[\"PRODUCTION_COUNT\"],\n",
        "        output_cols=[\"PREDICTED_PRODUCTION\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "production_pipeline.fit(train_prod)\n",
        "print(\"✅ Production forecaster model trained\")\n",
        "\n",
        "# Evaluate and register\n",
        "prod_predictions = production_pipeline.predict(test_prod)\n",
        "mse = mean_squared_error(df=prod_predictions, y_true_col_names=\"PRODUCTION_COUNT\", y_pred_col_names=\"PREDICTED_PRODUCTION\")\n",
        "mae = mean_absolute_error(df=prod_predictions, y_true_col_names=\"PRODUCTION_COUNT\", y_pred_col_names=\"PREDICTED_PRODUCTION\")\n",
        "prod_metrics = {\"mse\": round(mse, 2), \"mae\": round(mae, 2)}\n",
        "print(f\"Model metrics: {prod_metrics}\")\n",
        "\n",
        "reg.log_model(\n",
        "    model=production_pipeline,\n",
        "    model_name=\"PRODUCTION_FORECASTER\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Forecasts monthly production throughput using Linear Regression based on historical patterns\",\n",
        "    metrics=prod_metrics\n",
        ")\n",
        "print(\"✅ Production forecaster model registered to Model Registry as PRODUCTION_FORECASTER\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All 3 models have been trained and registered to Snowflake Model Registry:\n",
        "\n",
        "| Model | Type | Output Column | Purpose |\n",
        "|-------|------|---------------|--------|\n",
        "| `PROGRAM_RISK_PREDICTOR` | RandomForestClassifier | `PREDICTED_RISK` | Predicts program schedule/cost risk |\n",
        "| `SUPPLIER_RISK_PREDICTOR` | RandomForestClassifier | `PREDICTED_RISK` | Identifies supplier performance risk |\n",
        "| `PRODUCTION_FORECASTER` | LinearRegression | `PREDICTED_PRODUCTION` | Forecasts monthly production |\n",
        "\n",
        "**Next Steps:**\n",
        "1. Run `sql/ml/07_create_model_wrapper_functions.sql` to create stored procedures that wrap these models\n",
        "2. Run `sql/agent/08_create_intelligence_agent.sql` to create the Intelligence Agent with ML tools\n",
        "3. Test the agent in Snowsight under AI & ML > Agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify all models are registered - reg.show_models() returns a pandas DataFrame, use print() not .show()\n",
        "print(\"=\" * 60)\n",
        "print(\"VERIFICATION: Models registered in Model Registry\")\n",
        "print(\"=\" * 60)\n",
        "models = reg.show_models()\n",
        "print(models)\n",
        "\n",
        "print(\"\\n✅ All 3 models registered successfully!\")\n",
        "print(\"   - PROGRAM_RISK_PREDICTOR\")\n",
        "print(\"   - SUPPLIER_RISK_PREDICTOR\")\n",
        "print(\"   - PRODUCTION_FORECASTER\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
